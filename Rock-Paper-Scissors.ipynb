âŠ–
In [17]:
!wget --no-check-certificate \
    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip \
    -O /tmp/rps.zip
  
!wget --no-check-certificate \
    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip \
    -O /tmp/rps-test-set.zip
--2019-02-13 22:46:40--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip
Resolving storage.googleapis.com... 2607:f8b0:4003:c0a::80, 64.233.171.128
Connecting to storage.googleapis.com|2607:f8b0:4003:c0a::80|:443... connected.
WARNING: cannot verify storage.googleapis.com's certificate, issued by 'CN=Google Internet Authority G3,O=Google Trust Services,C=US':
  Unable to locally verify the issuer's authority.
HTTP request sent, awaiting response... 200 OK
Length: 200682221 (191M) [application/zip]
Saving to: '/tmp/rps.zip'

/tmp/rps.zip        100%[=====================>] 191.38M   168MB/s   in 1.1s   

2019-02-13 22:46:41 (168 MB/s) - '/tmp/rps.zip' saved [200682221/200682221]

--2019-02-13 22:46:42--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip
Resolving storage.googleapis.com... 2607:f8b0:4003:c11::80, 74.125.127.128
Connecting to storage.googleapis.com|2607:f8b0:4003:c11::80|:443... connected.
WARNING: cannot verify storage.googleapis.com's certificate, issued by 'CN=Google Internet Authority G3,O=Google Trust Services,C=US':
  Unable to locally verify the issuer's authority.
HTTP request sent, awaiting response... 200 OK
Length: 29516758 (28M) [application/zip]
Saving to: '/tmp/rps-test-set.zip'

/tmp/rps-test-set.z 100%[=====================>]  28.15M   128MB/s   in 0.2s   

2019-02-13 22:46:43 (128 MB/s) - '/tmp/rps-test-set.zip' saved [29516758/29516758]

In [0]:
import os
import zipfile

local_zip = '/tmp/rps.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp/')
zip_ref.close()

local_zip = '/tmp/rps-test-set.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp/')
zip_ref.close()
In [19]:
rock_dir = os.path.join('/tmp/rps/rock')
paper_dir = os.path.join('/tmp/rps/paper')
scissors_dir = os.path.join('/tmp/rps/scissors')

print('total training rock images:', len(os.listdir(rock_dir)))
print('total training paper images:', len(os.listdir(paper_dir)))
print('total training scissors images:', len(os.listdir(scissors_dir)))

rock_files = os.listdir(rock_dir)
print(rock_files[:10])

paper_files = os.listdir(paper_dir)
print(paper_files[:10])

scissors_files = os.listdir(scissors_dir)
print(scissors_files[:10])
('total training rock images:', 840)
('total training paper images:', 840)
('total training scissors images:', 840)
['rock06ck02-084.png', 'rock01-024.png', 'rock06ck02-069.png', 'rock03-086.png', 'rock06ck02-033.png', 'rock01-058.png', 'rock03-036.png', 'rock01-086.png', 'rock07-k03-010.png', 'rock01-110.png']
['paper01-079.png', 'paper03-059.png', 'paper04-108.png', 'paper02-048.png', 'paper02-007.png', 'paper04-022.png', 'paper01-103.png', 'paper07-043.png', 'paper03-017.png', 'paper06-119.png']
['scissors04-003.png', 'testscissors03-082.png', 'scissors03-102.png', 'scissors02-004.png', 'testscissors02-080.png', 'scissors01-081.png', 'scissors02-053.png', 'scissors02-045.png', 'testscissors01-113.png', 'testscissors03-068.png']
In [20]:
%matplotlib inline

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

pic_index = 2

next_rock = [os.path.join(rock_dir, fname) 
                for fname in rock_files[pic_index-2:pic_index]]
next_paper = [os.path.join(paper_dir, fname) 
                for fname in paper_files[pic_index-2:pic_index]]
next_scissors = [os.path.join(scissors_dir, fname) 
                for fname in scissors_files[pic_index-2:pic_index]]

for i, img_path in enumerate(next_rock+next_paper+next_scissors):
  #print(img_path)
  img = mpimg.imread(img_path)
  plt.imshow(img)
  plt.axis('Off')
  plt.show()






In [21]:
import tensorflow as tf
import keras_preprocessing
from keras_preprocessing import image
from keras_preprocessing.image import ImageDataGenerator

TRAINING_DIR = "/tmp/rps/"
training_datagen = ImageDataGenerator(
      rescale = 1./255,
	  rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest')

VALIDATION_DIR = "/tmp/rps-test-set/"
validation_datagen = ImageDataGenerator(rescale = 1./255)

train_generator = training_datagen.flow_from_directory(
	TRAINING_DIR,
	target_size=(150,150),
	class_mode='categorical'
)

validation_generator = validation_datagen.flow_from_directory(
	VALIDATION_DIR,
	target_size=(150,150),
	class_mode='categorical'
)

model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 150x150 with 3 bytes color
    # This is the first convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The third convolution
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fourth convolution
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.5),
    # 512 neuron hidden layer
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])


model.summary()

model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

history = model.fit_generator(train_generator, epochs=25, validation_data = validation_generator, verbose = 1)

model.save("rps.h5")
Found 2520 images belonging to 3 classes.
Found 372 images belonging to 3 classes.
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_20 (Conv2D)           (None, 148, 148, 64)      1792      
_________________________________________________________________
max_pooling2d_20 (MaxPooling (None, 74, 74, 64)        0         
_________________________________________________________________
conv2d_21 (Conv2D)           (None, 72, 72, 64)        36928     
_________________________________________________________________
max_pooling2d_21 (MaxPooling (None, 36, 36, 64)        0         
_________________________________________________________________
conv2d_22 (Conv2D)           (None, 34, 34, 128)       73856     
_________________________________________________________________
max_pooling2d_22 (MaxPooling (None, 17, 17, 128)       0         
_________________________________________________________________
conv2d_23 (Conv2D)           (None, 15, 15, 128)       147584    
_________________________________________________________________
max_pooling2d_23 (MaxPooling (None, 7, 7, 128)         0         
_________________________________________________________________
flatten_5 (Flatten)          (None, 6272)              0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 6272)              0         
_________________________________________________________________
dense_10 (Dense)             (None, 512)               3211776   
_________________________________________________________________
dense_11 (Dense)             (None, 3)                 1539      
=================================================================
Total params: 3,473,475
Trainable params: 3,473,475
Non-trainable params: 0
_________________________________________________________________
Epoch 1/25
79/79==============================] - 20s 257ms/step - loss: 1.2037 - acc: 0.3786 - val_loss: 1.0084 - val_acc: 0.6344
Epoch 2/25
79/79==============================] - 19s 242ms/step - loss: 0.8781 - acc: 0.6000 - val_loss: 0.3174 - val_acc: 0.9946
Epoch 3/25
79/79==============================] - 20s 250ms/step - loss: 0.5636 - acc: 0.7595 - val_loss: 0.1306 - val_acc: 1.0000
Epoch 4/25
79/79==============================] - 19s 243ms/step - loss: 0.4033 - acc: 0.8397 - val_loss: 0.2548 - val_acc: 0.8414
Epoch 5/25
79/79==============================] - 19s 240ms/step - loss: 0.3114 - acc: 0.8897 - val_loss: 0.0518 - val_acc: 0.9866
Epoch 6/25
79/79==============================] - 20s 251ms/step - loss: 0.2161 - acc: 0.9278 - val_loss: 0.1461 - val_acc: 0.9409
Epoch 7/25
79/79==============================] - 19s 246ms/step - loss: 0.2107 - acc: 0.9282 - val_loss: 0.0579 - val_acc: 0.9892
Epoch 8/25
79/79==============================] - 19s 243ms/step - loss: 0.1796 - acc: 0.9345 - val_loss: 0.0487 - val_acc: 0.9812
Epoch 9/25
79/79==============================] - 20s 252ms/step - loss: 0.1681 - acc: 0.9468 - val_loss: 0.0209 - val_acc: 0.9946
Epoch 10/25
79/79==============================] - 20s 257ms/step - loss: 0.1286 - acc: 0.9532 - val_loss: 0.1703 - val_acc: 0.9328
Epoch 11/25
79/79==============================] - 19s 241ms/step - loss: 0.1457 - acc: 0.9532 - val_loss: 0.0287 - val_acc: 0.9919
Epoch 12/25
79/79==============================] - 19s 241ms/step - loss: 0.1053 - acc: 0.9687 - val_loss: 0.0737 - val_acc: 0.9704
Epoch 13/25
79/79==============================] - 20s 249ms/step - loss: 0.1216 - acc: 0.9603 - val_loss: 0.0290 - val_acc: 0.9866
Epoch 14/25
79/79==============================] - 19s 236ms/step - loss: 0.1651 - acc: 0.9532 - val_loss: 0.0918 - val_acc: 0.9758
Epoch 15/25
79/79==============================] - 19s 236ms/step - loss: 0.0996 - acc: 0.9659 - val_loss: 0.1870 - val_acc: 0.8978
Epoch 16/25
79/79==============================] - 20s 248ms/step - loss: 0.0804 - acc: 0.9702 - val_loss: 0.0228 - val_acc: 0.9839
Epoch 17/25
79/79==============================] - 19s 241ms/step - loss: 0.1079 - acc: 0.9659 - val_loss: 0.0448 - val_acc: 0.9785
Epoch 18/25
79/79==============================] - 19s 240ms/step - loss: 0.1005 - acc: 0.9667 - val_loss: 0.0431 - val_acc: 0.9812
Epoch 19/25
79/79==============================] - 19s 244ms/step - loss: 0.0983 - acc: 0.9698 - val_loss: 0.0627 - val_acc: 0.9785
Epoch 20/25
79/79==============================] - 20s 249ms/step - loss: 0.0830 - acc: 0.9738 - val_loss: 0.3355 - val_acc: 0.8575
Epoch 21/25
79/79==============================] - 19s 245ms/step - loss: 0.1141 - acc: 0.9647 - val_loss: 0.0584 - val_acc: 0.9731
Epoch 22/25
79/79==============================] - 19s 243ms/step - loss: 0.0803 - acc: 0.9750 - val_loss: 0.0380 - val_acc: 0.9812
Epoch 23/25
79/79==============================] - 20s 253ms/step - loss: 0.0762 - acc: 0.9754 - val_loss: 0.3842 - val_acc: 0.9167
Epoch 24/25
79/79==============================] - 19s 246ms/step - loss: 0.0781 - acc: 0.9758 - val_loss: 0.0176 - val_acc: 0.9892
Epoch 25/25
79/79==============================] - 19s 237ms/step - loss: 0.0708 - acc: 0.9810 - val_loss: 0.1145 - val_acc: 0.9543
In [22]:
import matplotlib.pyplot as plt
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()


plt.show()

<matplotlib.figure.Figure at 0x7f620e844e50>
In [26]:
import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()

for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150, 150))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)
  print(fn)
  print(classes)
Saving paper2.png to paper2 (1).png
Saving rock-hires2.png to rock-hires2.png
Saving scissors-hires2.png to scissors-hires2.png
Saving paper-hires2.png to paper-hires2.png
Saving paper-hires1.png to paper-hires1.png
Saving rock-hires1.png to rock-hires1 (1).png
Saving scissors-hires1.png to scissors-hires1.png
Saving scissors9.png to scissors9.png
Saving scissors8.png to scissors8.png
Saving scissors7.png to scissors7 (1).png
Saving rock9.png to rock9.png
Saving rock8.png to rock8.png
Saving rock7.png to rock7.png
Saving paper9.png to paper9.png
Saving paper8.png to paper8.png
Saving paper7.png to paper7.png
Saving scissors6.png to scissors6.png
Saving scissors5.png to scissors5.png
Saving scissors4.png to scissors4.png
Saving paper6.png to paper6.png
Saving paper5.png to paper5.png
Saving paper4.png to paper4.png
Saving rock6.png to rock6.png
Saving rock5.png to rock5.png
Saving rock4.png to rock4.png
Saving scissors3.png to scissors3.png
Saving scissors2.png to scissors2.png
Saving scissors1.png to scissors1.png
Saving paper3.png to paper3.png
Saving paper1.png to paper1.png
Saving rock3.png to rock3.png
Saving rock2.png to rock2.png
Saving rock1.png to rock1.png
scissors-hires1.png
[[ 0.  0.  1.]]
paper4.png
[[  2.77571414e-38   0.00000000e+00   1.00000000e+00]]
paper6.png
[[ 1.  0.  0.]]
scissors1.png
[[ 0.  0.  1.]]
scissors3.png
[[ 0.  0.  1.]]
scissors2.png
[[ 0.  0.  1.]]
scissors9.png
[[ 0.  0.  1.]]
rock7.png
[[ 0.  1.  0.]]
rock9.png
[[ 0.  1.  0.]]
rock8.png
[[ 0.  1.  0.]]
paper-hires1.png
[[ 1.  0.  0.]]
rock4.png
[[ 0.  1.  0.]]
paper5.png
[[ 0.  0.  1.]]
rock2.png
[[ 0.  1.  0.]]
paper9.png
[[ 0.  0.  1.]]
paper1.png
[[ 1.  0.  0.]]
rock6.png
[[ 0.  1.  0.]]
rock5.png
[[ 0.  1.  0.]]
scissors4.png
[[ 0.  0.  1.]]
rock-hires2.png
[[ 0.  1.  0.]]
scissors-hires2.png
[[ 0.  0.  1.]]
paper8.png
[[ 1.  0.  0.]]
paper-hires2.png
[[ 1.  0.  0.]]
rock3.png
[[ 0.  1.  0.]]
rock1.png
[[ 0.  1.  0.]]
paper3.png
[[ 0.  0.  1.]]
paper2.png
[[ 1.  0.  0.]]
scissors5.png
[[ 0.  0.  1.]]
scissors7.png
[[ 0.  0.  1.]]
scissors6.png
[[ 0.  0.  1.]]
rock-hires1.png
[[ 0.  1.  0.]]
scissors8.png
[[ 0.  0.  1.]]
paper7.png
[[ 1.  0.  0.]]
